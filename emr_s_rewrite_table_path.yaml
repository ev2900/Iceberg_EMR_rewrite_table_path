Description: CloudFormation Deployment of EMR Serverless for Icberg rewrite_table_path procedure

Parameters:
  DefaultVpcId:
    Description: The ID of the default VPC in your AWS account.
    Type: AWS::EC2::VPC::Id

  DefaultSubnetId:
    Type: AWS::EC2::Subnet::Id
    Description: The ID of the default subnet to use.

  DefaultSecurityGroup:
    Type: AWS::EC2::SecurityGroup::Id
    Description: The ID of the default security group to use.

Resources:
  #
  # S3 Bucket
  #
  S3:
    Type: AWS::S3::Bucket

  #
  # Lambda Function IAM Role
  # 
  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: "sts:AssumeRole"
      Policies:
        # Imporvement required - premissions need to be scoped down
        - PolicyName: Admin
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action: 
                  - '*'
                Resource: '*'
                
  #
  # Lambda Function to download Iceberg Jar files
  # 
  DownloadJARsScriptLambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: 'Download-Iceberg-Jar-and-Glue-Script-Rewrite-Table'
      Handler: index.lambda_handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Runtime: python3.8
      Code:
        ZipFile: |
          
          import cfnresponse
          import urllib3
          import boto3
          import os
          
          def lambda_handler(event, context):
  
            s3 = boto3.client('s3')
            http = urllib3.PoolManager()

            print('-- Event below --')
            print(event)
            print('--')

            if event['RequestType'] == 'Create':
              try:
                # AWS Bundle
                print('Downloading AWS bundle JAR ...')
                response = http.request('GET', 'https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-aws-bundle/1.10.0/iceberg-aws-bundle-1.10.0.jar', timeout=urllib3.Timeout(connect=15.0, read=60.0))
                print("AWS bundle JAR download HTTP status " + str(response.status))
      
                if response.status == 200:
                  with open('/tmp/iceberg-aws-bundle-1.10.0.jar', 'wb') as f:
                    f.write(response.data)
                  os.sync()
          
                s3.upload_file('/tmp/iceberg-aws-bundle-1.10.0.jar', os.environ['S3_BUCKET_NAME'], 'jars/iceberg-aws-bundle-1.10.0.jar')
      
                # Iceberg
                print('Downloading Iceberg bundle JAR ...')
                response = http.request('GET', 'https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-3.5_2.12/1.10.0/iceberg-spark-runtime-3.5_2.12-1.10.0.jar', timeout=urllib3.Timeout(connect=15.0, read=60.0))
                print("Iceberg JAR download HTTP status " + str(response.status))
      
                if response.status == 200:
                  with open('/tmp/iceberg-spark-runtime-3.5_2.12-1.10.0.jar', 'wb') as f:
                    f.write(response.data)
                  os.sync()
          
                s3.upload_file('/tmp/iceberg-spark-runtime-3.5_2.12-1.10.0.jar', os.environ['S3_BUCKET_NAME'], 'jars/iceberg-spark-runtime-3.5_2.12-1.10.0.jar')
  
                # Glue Job Script
                copy_source = {
                  'Bucket': 'sharkech-public',
                  'Key': 'misc-public/rewrite_table_path.py'
                }
  
                s3.copy_object(CopySource = copy_source, Bucket = os.environ['S3_BUCKET_NAME'], Key = 'scripts/rewrite_table_path.py')
                
                # Return success status to cloudformation 
                responseData = {'Status': 'SUCCESS', 'StackId': event['StackId'], 'RequestId': event['RequestId'], 'LogicalResourceId': event['LogicalResourceId'], 'PhysicalResourceId': ''}
                cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)

                 # Return lambda response
                return {
                  'statusCode': 200,
                  'body': 'successfully download JAR files and glue script to S3'
                }
                
              except Exception as e:
                print('-- Error for create request type --')
                print(e)
                print('--')

                responseData = {'Status': 'FAILURE', 'StackId': event['StackId'], 'RequestId': event['RequestId'], 'LogicalResourceId': event['LogicalResourceId'], 'PhysicalResourceId': ''}
                cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)

                # Return lambda response
                return {
                  'statusCode': 400,
                  'body': 'failed to download JAR files and glue script to S3'
                }

            elif event['RequestType'] == 'Delete':
              try:
                s3 = boto3.resource('s3')
                bucket = s3.Bucket(os.environ['S3_BUCKET_NAME'])
              
                for prefix in ['jars', 'scripts', 'iceberg']:
                  objects_to_delete = bucket.objects.filter(Prefix=prefix)
                  objects_to_delete.delete()

                responseData = {'Status': 'SUCCESS', 'StackId': event['StackId'], 'RequestId': event['RequestId'], 'LogicalResourceId': event['LogicalResourceId'], 'PhysicalResourceId': ''}
                cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)
                
              except Exception as e:
                print('-- Error for delete request type --')
                print(e)
                print('--')

                responseData = {'Status': 'FAILURE', 'StackId': event['StackId'], 'RequestId': event['RequestId'], 'LogicalResourceId': event['LogicalResourceId'], 'PhysicalResourceId': ''}
                cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)

                # Return lambda response
                return {
                  'statusCode': 400,
                  'body': 'failed to delete files from S3'
                }          
      Timeout: 300
      MemorySize: 2048
      EphemeralStorage: 
        Size: 5120
      Environment:
        Variables:
          S3_BUCKET_NAME: !Ref S3
  
  #
  # Customer resource to execute the load CSV lambda function
  #
  DownloadJARsLambdaFunctionCustomResource:
    Type: AWS::CloudFormation::CustomResource
    DependsOn: DownloadJARsScriptLambdaFunction
    Version: 1.0
    Properties:
      ServiceToken: !GetAtt DownloadJARsScriptLambdaFunction.Arn
  
  #
  # EMR Serverless application
  #
  EMRServerlessApplication:
    Type: AWS::EMRServerless::Application
    Properties:
      Name: emr-serverless-app
      ReleaseLabel: emr-7.10.0               
      Type: Spark                            
      AutoStartConfiguration:
        Enabled: true
      AutoStopConfiguration:
        Enabled: true
        IdleTimeoutMinutes: 15
      InitialCapacity:
        - Key: Driver
          Value:
              WorkerCount: 1
              WorkerConfiguration:
                Cpu: "4 vCPU"
                Memory: "16 GB"
        - Key: Executor
          Value:
              WorkerCount: 2
              WorkerConfiguration:
                Cpu: "4 vCPU"
                Memory: "16 GB"
      MaximumCapacity:
        Cpu: "32 vCPU"
        Memory: "128 GB"
      MaximumCapacity:
        Cpu: "32 vCPU"
        Memory: "128 GB"

  #
  # EMR Studio IAM Role
  #
  EMRStudioExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: elasticmapreduce.amazonaws.com
            Action: "sts:AssumeRole"
      Policies:
        # Imporvement required - premissions need to be scoped down
        - PolicyName: Admin
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - '*'
                Resource: '*'

  #
  # EMR Studio
  #
  EMRStudio:
    Type: AWS::EMR::Studio
    Properties:
      Name: 'EMRStudio_Iceberg'
      DefaultS3Location: !Join
        - ''
        - - 's3://'
          - !Ref S3
          - '/emrstudio/'
      AuthMode: 'IAM'
      ServiceRole: !GetAtt EMRStudioExecutionRole.Arn
      VpcId: !Ref DefaultVpcId
      SubnetIds:
        - !Ref DefaultSubnetId
      EngineSecurityGroupId: !Ref DefaultSecurityGroup
      WorkspaceSecurityGroupId: !Ref DefaultSecurityGroup

  #
  # EMR Serverless Runtime IAM Role
  # 
  EMRServerlessRunTimeRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: emr-serverless.amazonaws.com
            Action: "sts:AssumeRole"
      Policies:
        # Imporvement required - premissions need to be scoped down
        - PolicyName: Admin
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action: 
                  - '*'
                Resource: '*'
